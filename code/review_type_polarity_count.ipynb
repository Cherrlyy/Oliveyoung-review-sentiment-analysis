{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kss import split_sentences\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000000192697</td>\n",
       "      <td>[2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...</td>\n",
       "      <td>2023.11.30</td>\n",
       "      <td>피부타입  복합성요 토너 없이는 못살아요겨울 강철 추위도 버티게 해주는 저의 최애템...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A000000192697</td>\n",
       "      <td>[2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...</td>\n",
       "      <td>2023.11.28</td>\n",
       "      <td>다른 토너로 갈아탔다가 환절기 때 피부가 뒤집어지고 너무 안 돌아와서 다시 구매합니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A000000192697</td>\n",
       "      <td>[2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...</td>\n",
       "      <td>2023.11.26</td>\n",
       "      <td>전 이거 하나로 흡토 닦토 다 하고 있어요 자극없이 순하고 용량도 많아서 밤마다 화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000000192697</td>\n",
       "      <td>[2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...</td>\n",
       "      <td>2023.11.19</td>\n",
       "      <td>자극없이 순하고 결 정돈하기 좋은 토너예요민감성 지성 복합성 다 두루 쓰기 좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000000192697</td>\n",
       "      <td>[2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...</td>\n",
       "      <td>2023.11.11</td>\n",
       "      <td>이제는 제 화장대에 없는게 말이 안되는 재구매템정말이지 공병만 몇 십병 만들었을거에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32396</th>\n",
       "      <td>A000000139057</td>\n",
       "      <td>아벤느 이드랑스 딥 모이스트로션 200ml</td>\n",
       "      <td>2021.01.24</td>\n",
       "      <td>후기보고 살짝 콧물 스킨토너 좀 점성이 있는줄 알았는데 막상 받아보니 아주 살짝있어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32397</th>\n",
       "      <td>A000000139057</td>\n",
       "      <td>아벤느 이드랑스 딥 모이스트로션 200ml</td>\n",
       "      <td>2021.01.22</td>\n",
       "      <td>토너를 오래 찾던 중에 겨울에 쓸만한게 이 제품이 딱이더라구요 저는 겨울되면 얼굴이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32398</th>\n",
       "      <td>A000000139057</td>\n",
       "      <td>아벤느 이드랑스 딥 모이스트로션 200ml</td>\n",
       "      <td>2021.01.22</td>\n",
       "      <td>속당김이 엄청 심한편이라 수분크림  에센스를 발라도 겨울엔 겉에만 유분기가있지 수분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32399</th>\n",
       "      <td>A000000139057</td>\n",
       "      <td>아벤느 이드랑스 딥 모이스트로션 200ml</td>\n",
       "      <td>2021.01.11</td>\n",
       "      <td>수부지 피부 지성피부에 아벤느 제품이 좋다고해서 처음 구매해봤는데 타 제품들과 달리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32400</th>\n",
       "      <td>A000000139057</td>\n",
       "      <td>아벤느 이드랑스 딥 모이스트로션 200ml</td>\n",
       "      <td>2021.01.10</td>\n",
       "      <td>제 피부는 극건성이라 왠만한 토너들은 건조한 편이에요 그렇다고 크림 스킨을 쓰면 닥...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32401 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               name  \\\n",
       "0      A000000192697  [2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...   \n",
       "1      A000000192697  [2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...   \n",
       "2      A000000192697  [2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...   \n",
       "3      A000000192697  [2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...   \n",
       "4      A000000192697  [2023어워즈/3년연속] 아누아 어성초 77 수딩 토너 350ml 어워즈 한정 기...   \n",
       "...              ...                                                ...   \n",
       "32396  A000000139057                            아벤느 이드랑스 딥 모이스트로션 200ml   \n",
       "32397  A000000139057                            아벤느 이드랑스 딥 모이스트로션 200ml   \n",
       "32398  A000000139057                            아벤느 이드랑스 딥 모이스트로션 200ml   \n",
       "32399  A000000139057                            아벤느 이드랑스 딥 모이스트로션 200ml   \n",
       "32400  A000000139057                            아벤느 이드랑스 딥 모이스트로션 200ml   \n",
       "\n",
       "             date                                            content  \n",
       "0      2023.11.30  피부타입  복합성요 토너 없이는 못살아요겨울 강철 추위도 버티게 해주는 저의 최애템...  \n",
       "1      2023.11.28  다른 토너로 갈아탔다가 환절기 때 피부가 뒤집어지고 너무 안 돌아와서 다시 구매합니...  \n",
       "2      2023.11.26  전 이거 하나로 흡토 닦토 다 하고 있어요 자극없이 순하고 용량도 많아서 밤마다 화...  \n",
       "3      2023.11.19      자극없이 순하고 결 정돈하기 좋은 토너예요민감성 지성 복합성 다 두루 쓰기 좋아요  \n",
       "4      2023.11.11  이제는 제 화장대에 없는게 말이 안되는 재구매템정말이지 공병만 몇 십병 만들었을거에...  \n",
       "...           ...                                                ...  \n",
       "32396  2021.01.24  후기보고 살짝 콧물 스킨토너 좀 점성이 있는줄 알았는데 막상 받아보니 아주 살짝있어...  \n",
       "32397  2021.01.22  토너를 오래 찾던 중에 겨울에 쓸만한게 이 제품이 딱이더라구요 저는 겨울되면 얼굴이...  \n",
       "32398  2021.01.22  속당김이 엄청 심한편이라 수분크림  에센스를 발라도 겨울엔 겉에만 유분기가있지 수분...  \n",
       "32399  2021.01.11  수부지 피부 지성피부에 아벤느 제품이 좋다고해서 처음 구매해봤는데 타 제품들과 달리...  \n",
       "32400  2021.01.10  제 피부는 극건성이라 왠만한 토너들은 건조한 편이에요 그렇다고 크림 스킨을 쓰면 닥...  \n",
       "\n",
       "[32401 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = pd.read_csv('review_final_preprocessed.csv', encoding='UTF-8')\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "soothing = set(['진정', '자극', '트러블', '여드름', '순하다', '효과', '좁쌀', '예민', '제거', '나다', '민감',\n",
    "                     '민감성', '피지', '올라오다', '어성초', '붉다', '티트리', '가라', '앉다' ])\n",
    "\n",
    "moisturizing = set(['보습', '건조', '건성', '수분', '흡수', '촉촉하다', '타입', '겨울', '지성', '여름',\n",
    "                         '수분감', '속건조', '복합성' '채우다' '촉촉' '수부지', ])\n",
    "skin = set(['각질', '모공', '피부결', '크다', '부드럽다', '정돈', '화장솜', '장벽', '탄력', '보호', '보들보들'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joy\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "C:\\Users\\Joy\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "C:\\Users\\Joy\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "C:\\Users\\Joy\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator PCA from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('./model/model.pk1')\n",
    "model_pca_5000 = joblib.load('./model/model_pca_5000.pk1')\n",
    "model_pca_2500 = joblib.load('./model/model_pca_2500.pk1')\n",
    "\n",
    "tf_idf_vec = joblib.load('./model/tf_idf_vec.pk1')\n",
    "pca_5000 = joblib.load('./model/pca_5000.pk1')\n",
    "pca_2500 = joblib.load('./model/pca_2500.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    vector = tf_idf_vec.transform([sentence]).toarray()\n",
    "    prediction = model.predict(vector)[0]\n",
    "    return prediction\n",
    "\n",
    "sentence = \"보습은 별로\"\n",
    "predict_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df = pd.DataFrame({\"soothing\":[0 for i in range(len(review))],\n",
    "               \"moisturizing\":[0 for i in range(len(review))],\n",
    "               \"skin\":[0 for i in range(len(review))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(review)):\n",
    "    # 디버깅\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    # 돌아오기\n",
    "    context = split_sentences(review[\"content\"][i])\n",
    "    for text in context:\n",
    "        for efficient_type in type_df.columns:\n",
    "            if any(keyword in text for keyword in eval(efficient_type)):\n",
    "                type_df.loc[i, efficient_type] = type_df.loc[i, efficient_type] + predict_sentiment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df.to_csv('review_type_polarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - PC5000 까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment_pca_5000(sentence):\n",
    "    vector = tf_idf_vec.transform([sentence]).toarray()\n",
    "    vector = pca_5000.transform(pd.DataFrame(vector))\n",
    "    prediction = model_pca_5000.predict(vector)[0]\n",
    "    return prediction\n",
    "\n",
    "sentence = \"보습은 그냥 그래요\"\n",
    "predict_sentiment_pca_5000(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df_pca_5000 = pd.DataFrame({\"soothing\":[0 for i in range(len(review))],\n",
    "               \"moisturizing\":[0 for i in range(len(review))],\n",
    "               \"skin\":[0 for i in range(len(review))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(review)):\n",
    "    # 디버깅\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    # 돌아오기\n",
    "    context = split_sentences(review[\"content\"][i])\n",
    "    for text in context:\n",
    "        for efficient_type in type_df_pca_5000.columns:\n",
    "            if any(keyword in text for keyword in eval(efficient_type)):\n",
    "                type_df_pca_5000.loc[i, efficient_type] = type_df_pca_5000.loc[i, efficient_type] + predict_sentiment_pca_5000(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - PC2500 까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment_pca_2500(sentence):\n",
    "    vector = tf_idf_vec.transform([sentence]).toarray()\n",
    "    vector = pca_2500.transform(pd.DataFrame(vector))\n",
    "    prediction = model_pca_2500.predict(vector)[0]\n",
    "    return prediction\n",
    "\n",
    "sentence = \"보습은 그냥 그래요\"\n",
    "predict_sentiment_pca_2500(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df_pca_2500 = pd.DataFrame({\"soothing\":[0 for i in range(len(review))],\n",
    "               \"moisturizing\":[0 for i in range(len(review))],\n",
    "               \"skin\":[0 for i in range(len(review))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(review)):\n",
    "    # 디버깅\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    # 돌아오기\n",
    "    context = split_sentences(review[\"content\"][i])\n",
    "    for text in context:\n",
    "        for efficient_type in type_df_pca_2500.columns:\n",
    "            if any(keyword in text for keyword in eval(efficient_type)):\n",
    "                type_df_pca_2500.loc[i, efficient_type] = type_df_pca_2500.loc[i, efficient_type] + predict_sentiment_pca_2500(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df_pca_2500.to_csv('review_type_polarity_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soothing</th>\n",
       "      <th>moisturizing</th>\n",
       "      <th>skin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32396</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32397</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32400</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32401 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       soothing  moisturizing  skin\n",
       "0             0             1     0\n",
       "1             1             0     0\n",
       "2             1             0     2\n",
       "3             2             1     1\n",
       "4             1             2     0\n",
       "...         ...           ...   ...\n",
       "32396         1             3     0\n",
       "32397         0             3     0\n",
       "32398         0             1     0\n",
       "32399         1             1     0\n",
       "32400         1             0     0\n",
       "\n",
       "[32401 rows x 3 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_df_pca_2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
